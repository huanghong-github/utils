{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "\n",
    "\n",
    "class Onnx_Module(ort.InferenceSession):\n",
    "    \"\"\"\n",
    "    onnx 推理模型\n",
    "    provider: 优先使用 GPU\n",
    "    \"\"\"\n",
    "\n",
    "    provider = ort.get_available_providers()[1 if ort.get_device() == \"GPU\" else 0]\n",
    "\n",
    "    def __init__(self, file):\n",
    "        super(Onnx_Module, self).__init__(file, providers=[self.provider])\n",
    "        # 参考: ort.NodeArg\n",
    "        self.inputs = [node.name for node in self.get_inputs()]\n",
    "        self.outputs = [node.name for node in self.get_outputs()]\n",
    "\n",
    "    def __call__(self, *arrays):\n",
    "        input_feed = {name: x for name, x in zip(self.inputs, arrays)}\n",
    "        return self.run(self.outputs, input_feed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FasterRCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "device = \"cpu\"\n",
    "classes = {1: \"fire\", 2: \"smoke\"}\n",
    "\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(\n",
    "    weights=None, weights_backbone=None\n",
    ")\n",
    "\n",
    "num_classes = 3\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "WEIGHTS_FILE = r\"D:\\nn\\code\\ckpt\\faster_rcnn_state_2.pth\"\n",
    "model.load_state_dict(torch.load(WEIGHTS_FILE, map_location=\"cpu\"))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "image = torch.rand([1, 3, 416, 416])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 固定输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# onnx算子 https://github.com/onnx/onnx/blob/main/docs/Operators.md\n",
    "# 输入尺寸固定\n",
    "torch.onnx.export(model, image, \"fasterrcnn.onnx\", opset_version=11)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 动态输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_name = \"input\"\n",
    "output_name = \"output\"\n",
    "# https://blog.csdn.net/LimitOut/article/details/107117759\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    image,\n",
    "    \"fasterrcnn.onnx\",\n",
    "    opset_version=11,\n",
    "    input_names=[input_name],\n",
    "    output_names=[output_name],\n",
    "    dynamic_axes={\n",
    "        input_name: {0: \"batch_size\", 2: \"in_width\", 3: \"int_height\"},\n",
    "        output_name: {0: \"batch_size\", 2: \"out_width\", 3: \"out_height\"},\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def read_img(imgpath, size=(640, 640)):\n",
    "    img = cv2.imread(imgpath, cv2.IMREAD_COLOR)\n",
    "    img = cv2.resize(img, size)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    imdata = img.astype(np.float32) / 255.0\n",
    "    # 加上batch_size\n",
    "    imdata = np.expand_dims(imdata, axis=0)\n",
    "    # 将通道转到第二维\n",
    "    imdata = np.transpose(imdata, (0, 3, 1, 2))\n",
    "    return img, imdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from box import Box\n",
    "\n",
    "model = Onnx_Module(\"fasterrcnn.onnx\")\n",
    "\n",
    "imgpath = r\"4.jpg\"\n",
    "\n",
    "img, im_data = read_img(imgpath)\n",
    "\n",
    "# im = torch.from_numpy(im)\n",
    "# 加上batch_size\n",
    "# im = im.unsqueeze(0)\n",
    "# 将通道转到第二维\n",
    "# im = im.permute(0, 3, 1, 2).numpy()\n",
    "\n",
    "res = model(im_data)\n",
    "boxes = [Box(*res[0][i], classes[res[1][i]]) for i in range(len(res[0]))]\n",
    "\n",
    "for box in boxes:\n",
    "    rect = plt.Rectangle(\n",
    "        xy=(box.xmin, box.ymin),\n",
    "        width=box.xmax - box.xmin,\n",
    "        height=box.ymax - box.ymin,\n",
    "        edgecolor=\"r\",\n",
    "        linewidth=1,\n",
    "        fill=False,\n",
    "    )\n",
    "    plt.text(\n",
    "        x=box.xmin,\n",
    "        y=box.ymin,\n",
    "        s=box.name,\n",
    "        fontsize=10,\n",
    "        color=\"r\",\n",
    "        style=\"italic\",\n",
    "        weight=\"light\",\n",
    "    )\n",
    "    plt.gca().add_patch(rect)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = [\n",
    "    \"fire\",\n",
    "]  # coco80类别\n",
    "\n",
    "\n",
    "def pynms(dets, thresh):  # 非极大抑制\n",
    "    x1 = dets[:, 0]\n",
    "    y1 = dets[:, 1]\n",
    "    x2 = dets[:, 2]\n",
    "    y2 = dets[:, 3]\n",
    "    areas = (y2 - y1 + 1) * (x2 - x1 + 1)\n",
    "    scores = dets[:, 4]\n",
    "    keep = []\n",
    "    index = scores.argsort()[::-1]  # 置信度从大到小排序（下标）\n",
    "\n",
    "    while index.size > 0:\n",
    "        i = index[0]\n",
    "        keep.append(i)\n",
    "\n",
    "        x11 = np.maximum(x1[i], x1[index[1:]])  # 计算相交面积\n",
    "        y11 = np.maximum(y1[i], y1[index[1:]])\n",
    "        x22 = np.minimum(x2[i], x2[index[1:]])\n",
    "        y22 = np.minimum(y2[i], y2[index[1:]])\n",
    "\n",
    "        w = np.maximum(0, x22 - x11 + 1)  # 当两个框不想交时x22 - x11或y22 - y11 为负数，\n",
    "        # 两框不相交时把相交面积置0\n",
    "        h = np.maximum(0, y22 - y11 + 1)  #\n",
    "\n",
    "        overlaps = w * h\n",
    "        ious = overlaps / (areas[i] + areas[index[1:]] - overlaps)  # 计算IOU\n",
    "\n",
    "        idx = np.where(ious <= thresh)[0]  # IOU小于thresh的框保留下来\n",
    "        index = index[idx + 1]  # 下标以1开始\n",
    "        print(index)\n",
    "\n",
    "    return keep\n",
    "\n",
    "\n",
    "def xywh2xyxy(x):\n",
    "    # [x, y, w, h] to [x1, y1, x2, y2]\n",
    "    y = np.copy(x)\n",
    "    y[:, 0] = x[:, 0] - x[:, 2] / 2\n",
    "    y[:, 1] = x[:, 1] - x[:, 3] / 2\n",
    "    y[:, 2] = x[:, 0] + x[:, 2] / 2\n",
    "    y[:, 3] = x[:, 1] + x[:, 3] / 2\n",
    "    return y\n",
    "\n",
    "\n",
    "def filter_box(org_box, conf_thres, iou_thres):  # 过滤掉无用的框\n",
    "    org_box = np.squeeze(org_box)  # 删除为1的维度\n",
    "    conf = org_box[..., 4] > conf_thres  # 删除置信度小于conf_thres的BOX\n",
    "    # print(conf)\n",
    "    box = org_box[conf == True]\n",
    "    cls_cinf = box[..., 5:]\n",
    "    cls = []\n",
    "    for i in range(len(cls_cinf)):\n",
    "        cls.append(int(np.argmax(cls_cinf[i])))\n",
    "    all_cls = list(set(cls))  # 删除重复的类别\n",
    "    output = []\n",
    "    for i in range(len(all_cls)):\n",
    "        curr_cls = all_cls[i]\n",
    "        curr_cls_box = []\n",
    "        curr_out_box = []\n",
    "        for j in range(len(cls)):\n",
    "            if cls[j] == curr_cls:\n",
    "                box[j][5] = curr_cls  # 将第6列元素替换为类别下标\n",
    "                curr_cls_box.append(box[j][:6])  # 当前类别的BOX\n",
    "        curr_cls_box = np.array(curr_cls_box)\n",
    "        curr_cls_box = xywh2xyxy(curr_cls_box)\n",
    "        curr_out_box = pynms(curr_cls_box, iou_thres)  # 经过非极大抑制后输出的BOX下标\n",
    "        for k in curr_out_box:\n",
    "            output.append(curr_cls_box[k])  # 利用下标取出非极大抑制后的BOX\n",
    "    output = np.array(output)\n",
    "    return output\n",
    "\n",
    "\n",
    "def draw(image, box_data):  # 画图\n",
    "    boxes = box_data[..., :4].astype(np.int32)  # 取整方便画框\n",
    "    scores = box_data[..., 4]\n",
    "    classes = box_data[..., 5].astype(np.int32)  # 下标取整\n",
    "\n",
    "    for box, score, cl in zip(boxes, scores, classes):\n",
    "        top, left, right, bottom = box\n",
    "        print(\"class: {}, score: {}\".format(CLASSES[cl], score))\n",
    "        print(\n",
    "            \"box coordinate left,top,right,down: [{}, {}, {}, {}]\".format(\n",
    "                top, left, right, bottom\n",
    "            )\n",
    "        )\n",
    "\n",
    "        cv2.rectangle(image, (top, left), (right, bottom), (255, 0, 0), 2)\n",
    "        cv2.putText(\n",
    "            image,\n",
    "            \"{0} {1:.2f}\".format(CLASSES[cl], score),\n",
    "            (top, left),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.6,\n",
    "            (0, 0, 255),\n",
    "            2,\n",
    "        )\n",
    "\n",
    "\n",
    "model = Onnx_Module(r\"yolov5.onnx\")\n",
    "imgpath = r\"4.jpg\"\n",
    "img, im_data = read_img(imgpath)\n",
    "output = model(im_data)\n",
    "\n",
    "outbox = filter_box(output, 0.5, 0.5)\n",
    "draw(img, outbox)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

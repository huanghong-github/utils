{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device='cpu'\n",
    "classes={1:'fire',2:'smoke'}\n",
    "\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=None)\n",
    "\n",
    "WEIGHTS_FILE = r\"D:\\nn\\code\\ckpt\\faster_rcnn_state_2.pth\"\n",
    "\n",
    "num_classes = 3\n",
    "\n",
    "# get number of input features for the classifier\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "# replace the pre-trained head with a new one\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "# Load the traines weights\n",
    "model.load_state_dict(torch.load(WEIGHTS_FILE, map_location='cpu'))\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "image = torch.rand([1, 3, 416, 416])\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 固定输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# onnx算子 https://github.com/onnx/onnx/blob/main/docs/Operators.md\n",
    "# 输入尺寸固定\n",
    "torch.onnx.export(model, \n",
    "                  image, \n",
    "                  'fasterrcnn.onnx',\n",
    "                  opset_version = 11)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 动态输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_name = 'input'\n",
    "output_name = 'output'\n",
    "# 输入尺寸不固定\n",
    "torch.onnx.export(model, \n",
    "                 image, \n",
    "                 \"fasterrcnn.onnx\",\n",
    "                 opset_version=11,\n",
    "                 input_names=[input_name],\n",
    "                 output_names=[output_name],\n",
    "                 dynamic_axes={\n",
    "                     input_name: {0: 'batch_size', 2: 'in_width', 3: 'int_height'},\n",
    "                     output_name: {0: 'batch_size', 2: 'out_width', 3: 'out_height'}}\n",
    "                 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## onnx推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Onnx_Module(ort.InferenceSession):\n",
    "    ''' onnx 推理模型\n",
    "        provider: 优先使用 GPU'''\n",
    "    provider = ort.get_available_providers()[\n",
    "        1 if ort.get_device() == 'GPU' else 0]\n",
    " \n",
    "    def __init__(self, file):\n",
    "        super(Onnx_Module, self).__init__(file, providers=[self.provider])\n",
    "        # 参考: ort.NodeArg\n",
    "        self.inputs = [node_arg.name for node_arg in self.get_inputs()]\n",
    "        self.outputs = [node_arg.name for node_arg in self.get_outputs()]\n",
    " \n",
    "    def __call__(self, *arrays):\n",
    "        input_feed = {name: x for name, x in zip(self.inputs, arrays)}\n",
    "        return self.run(self.outputs, input_feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[306.73575, 361.15707, 544.3265 , 477.9342 ],\n",
      "       [290.35562, 260.72772, 324.5933 , 456.56262],\n",
      "       [862.0033 , 118.4404 , 881.1725 , 141.63399]], dtype=float32), array([1, 1, 1], dtype=int64), array([0.9768057, 0.9387695, 0.7504843], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "model = Onnx_Module('fasterrcnn.onnx')\n",
    "\n",
    "imgpath=r'D:\\nn\\code\\datasets\\fire\\test\\20230322101540.jpg'\n",
    "img = cv2.imread(imgpath, cv2.IMREAD_COLOR)\n",
    "# img=cv2.resize(img,(416,416))\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "\n",
    "\n",
    "img /= 255.0\n",
    "img = torch.from_numpy(img)\n",
    "img = img.unsqueeze(0)\n",
    "img = img.permute(0,3,1,2).numpy()\n",
    "\n",
    "res=model(img)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "classes={1:'fire',2:'smoke'}\n",
    "sample = cv2.imread(imgpath, cv2.IMREAD_COLOR)\n",
    "# sample=cv2.resize(sample,(416,416))\n",
    "sample = cv2.cvtColor(sample, cv2.COLOR_BGR2RGB).astype(np.int32)\n",
    "\n",
    "boxs,names,scores = res\n",
    "boxs=boxs.astype(np.int32)\n",
    "for i,box in enumerate(boxs):\n",
    "    cv2.rectangle(img=sample,\n",
    "                  pt1=(box[0], box[1]),\n",
    "                  pt2=(box[2], box[3]),\n",
    "                  color=(0, 220, 0), \n",
    "                  thickness=2)\n",
    "    cv2.putText(img=sample, \n",
    "                text=classes[names[i]], \n",
    "                org=(box[0],box[1]-5),\n",
    "                fontFace=cv2.FONT_HERSHEY_COMPLEX,\n",
    "                fontScale=0.7,\n",
    "                color=(220,0,0),\n",
    "                thickness=1,\n",
    "                lineType=cv2.LINE_AA)  \n",
    "\n",
    "plt.axis('off')\n",
    "plt.imshow(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
